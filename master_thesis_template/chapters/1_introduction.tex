%!TEX root = ../master_thesis.tex
\chapter{Introduction}
\label{ch:introduction}



Generative models (GM) deal with the estimation of probability distribution of data. In recent years GM have attracted a lot of interest mainly due to advancement in deep learning methods and computational resources. In \cite{goodfellow2014generative} proposed generative adversarial network (GAN) which efficiently learns to generate samples from high dimensional probability distribution in an adversarial setting. 

%This is mainly due to the high sampling rate of speech signals which make it computationally challenging to generate time domain signal. Though some generative models like WaveNet work in time domain but they are very slow in inference time and thus are not suitable in real time.

%At last to evaluate the quality of generated samples we train a speaker detection system. We use it to map generated samples to embedding space and evaluate the diversity using KL divergence similar to inception score. To compare the quality of generated and true samples we coFr\'{e}chet dista
Our results show the effectiveness of approach in doing cross domain adaptation. We evaluate our generative models


In our work we  following ways: (i) Our network inspired by UNIT architecture works on shared latent space assumption. (ii) We impose the constraint the generated samples. This allows faster and better quality of phase reconstruction. (iii) Our evaluation is conducted on LibriSpeech~\cite{} corpus