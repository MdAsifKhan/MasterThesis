%!TEX root = ../master_thesis.tex
% \abstract
\chapter*{\centering \Large Abstract}
\label{abstract}
\addcontentsline{toc}{chapter}{Abstract}
One key problem often encountered in developing a machine learning (ML) model is its robustness to the situation at test time which was limited by data in the training time. For a model to generalize well at test time requires training on a large number of diverse samples. Domain adaptation is an approach to translate data from the source domain to the target domain which later can be used to augment the learning process and develop robust ML systems. The recent advancement in generative models provide an end to end framework for domain adaptation. The unsupervised image to image translation (UNIT) proposed an idea of shared latent space and cycle consistency loss which allows to translate images from one domain to another when paired data is not available. The idea has been extensively explored for images with an application like generating a full object image with just a sketch of an image. In this work we build on this idea and extend it to speech signals. Specifically, we target the problem of voice conversion where our network can translate voice of male speaker to that of a female speaker and vice versa. The existence of such a network can be used to augment and improve automatic speech recognition (ASR) systems. In addition, it can be used for privacy in an end-to-end dialogue system where end users prefer not to reveal their voice to the system.  

In this work we work with spectrogram representation of speech data. The spectrogram consists of two parts: magnitude and phase information. The speech signals are highly periodic and have irregular discontinuities which makes it difficult for deep neural networks to learn meaningful features from phase information. One common approach is to use the magnitude representation and reconstruct phase  using iterative algorithms like Griffin Lim. The iterative method exploits the consistency of spectrogram to find the phase representation that allows to reconstruct a closest time domain signal. However, finding such a reconstruction is an ill-posed problem and is only guaranteed if spectrogram is consistent. In our work we present two setups: (i) we use magnitude representation and reconstruct phase using iterative methods. In addition, following the work of~\cite{??} we use the consistency condition of spectrogram to define a loss term which constraints the network to generate consistent spectrogram (ii) We train our network to generate full spectrogram. Instead of using phase information we transform it to the instantaneous frequency (IF) which addresses the problem of discontinuities and periodicity. In addition, we propose a projection loss term inspired by the iterative operation of Griffin Lim.


  